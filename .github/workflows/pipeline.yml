name: Reddit GenAI Pipeline

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run pipeline
        env:
          CLIENT_ID: ${{ secrets.CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
        run: |
          python extract.py
          python transform.py
          python vectorize.py
          python index.py
          echo "âœ… Pipeline executed successfully."

      # save outputs for debugging
      - name: Upload cleaned data
        uses: actions/upload-artifact@v3
        with:
          name: cleaned-data
          path: data/processed/reddit_posts_cleaned.csv

      - name: Upload vectorized data
        uses: actions/upload-artifact@v3
        with:
          name: vectorized-data
          path: data/vectorized/*.parquet

      # save logs (stdout and stderr)
      - name: Upload logs
        if: always()
        run: |
          mkdir -p logs
          dmesg > logs/system.log || true
        continue-on-error: true
      - name: Upload logs
        uses: actions/upload-artifact@v3
        with:
          name: logs
          path: logs/