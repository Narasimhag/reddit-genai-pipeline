name: Reddit GenAI Pipeline

on:
  schedule:
    - cron: '0 9 * * *'
  workflow_dispatch:

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Set up project directories
        run: |
          mkdir -p data/raw
          mkdir -p data/processed
          mkdir -p data/vectorized

      - name: Run pipeline
        env:
          CLIENT_ID: ${{ secrets.CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
        run: |
          python src/extract.py
          python src/transform.py
          python src/vectorize.py
          python src/index.py
          echo "âœ… Pipeline executed successfully."

      # save outputs for debugging
      - name: Upload cleaned data
        uses: actions/upload-artifact@v4
        with:
          name: cleaned-data
          path: data/processed/reddit_posts_cleaned.csv

      - name: Upload vectorized data
        uses: actions/upload-artifact@v4
        with:
          name: vectorized-data
          path: data/vectorized/*.parquet

      # save logs (stdout and stderr)
      - name: Upload logs
        if: always()
        run: |
          mkdir -p logs
          dmesg > logs/system.log || true
        continue-on-error: true
      - name: Upload logs
        uses: actions/upload-artifact@v4
        with:
          name: logs
          path: logs/